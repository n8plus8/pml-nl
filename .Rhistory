f_train <- training[ , -nzv]
f_train <- f_train[ , colSums(is.na(f_train)) !> .5*nrow(f_train)] # total NA threshold set to 50%
f_train <- f_train[ , colSums(is.na(f_train)) < .5*nrow(f_train)] # total NA threshold set to 50%
str(f_train)
sum(is.na(f_train))
f_train <- training[ , -(1:5)] # f means filtered
f_train <- training[ , -nzv]
f_train <- f_train[ , colSums(is.na(f_train)) > .95*nrow(f_train)]
f_train <- training[ , -nzv]
f_train <- f_train[ , colSums(is.na(f_train)) < .95*nrow(f_train)]
str(f_train)
sum(is.na(f_train))
f_train <- training[ , -nzv]
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
sum(is.na(f_train))
training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
str(training) # y = "classe"
training$classe <- as.factor(training$classe)
f_train <- training[ , -(1:5)] # f means filtered
nzv <- nearZeroVar(f_train)
nzv
View(f_train)
f_train <- f-train[ , -nzv]
f_train <- f_train[ , -nzv]
sum(is.na(f_train)) # looks like all columns with NAs were dropped. great.
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
sum(is.na(f_train)) # looks like all columns with NAs were dropped. great.
str(f_train)
unique(training$raw_timestamp_part_1)
View(training)
View(training)
table(training$classe)
str(f_train)
is.integer(f_train$num_window)
unique(f_train$num_window)
count(unique(f_train$num_window))
length(unique(f_train$num_window))
apply(f_train, 2, function(x) length(unique(x)))
apply(f_train, 2, function(x) length(unique(x))) < 10
f_train <- training[ , -(1:5)] # f means filtered
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
sum(is.na(f_train)) # looks like all columns with NAs were dropped. great.
uc <- apply(f_train, 2, function(x) length(unique(x))) # unique counts
View(f_train)
colsums(f_train)
colsum(f_train)
colSums(f_train)
uc <- apply(f_train, function(x) length(unique(f_train)))
uc <- apply(f_train, 2, function(x) length(unique(f_train)))
uc <- apply(f_train, 2, function(x) length(unique(f_train)))
uc <- apply(f_train, 2, function(x) length(unique(x)))
uc
View(f_train)
length(f_train$kurtosis_roll_belt)
is_empty(f_train$kurtosis_roll_belt)
sum(f_train$kurtosis_roll_belt)
sum(f_train$kurtosis_roll_belt)
str(f_train$kurtosis_roll_belt)
unique(f_train$kurtosis_roll_belt)
sum(unique(f_train$kurtosis_roll_belt))
length(unique(f_train$kurtosis_roll_belt))
length(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt != ""]
length(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt != " "]
length(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt != ""]
f_train$kurtosis_roll_belt[1]
length(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt == ""]
sum(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt == ""]
(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt == ""]
length(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt == ""]
summary(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt == ""]
test <- (f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt == ""]
length(test)
rm(test)
dim(f_train$kurtosis_roll_belt)[f_train$kurtosis_roll_belt == ""]
nzv <- nearZeroVar(f_train)[ , -"classe"]
nzv <- nearZeroVar(f_train)[ , -88]
nzv <- nearZeroVar(f_train)
nzv
f_train <- f_train[ , -nzv]
View(f_train)
table(training$classe) # class balance seems to be ok
f_train <- training[ , -(1:5)] # f means filtered
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
rm(uc)
View(f_train)
f_train$kurtosis_roll_belt
f_train$kurtosis_roll_belt == ""
sum(f_train$kurtosis_roll_belt == "")
empties <- apply(f_train, 2, function(x) sum(x == "") > .95*nrow(f_train))
empties
test <- f_train[ , -empties]
View(test)
empties <- apply(f_train, 2, function(x) sum(x == "")) > .95*nrow(f_train)
test <- f_train[ , -empties]
empties
-empties
!empties
test <- f_train[ , !empties]
View(test)
rm(test)
sum(f_train == "")
str(f_train)
f_train <- f_train[ , !empties]
sum(f_train == "")
nzv <- nearZeroVar(f_train)
length(nearZeroVar(f_train))
nzv
uc <- apply(f_train, 2, function(x) length(unique(x)))
uc > 5
uc[uc < 5]
uc
table(f_train)[,1]
table(f_train$new_window
uc <- apply(f_train, 2, function(x) length(unique(x)))
dim(f_train) # 34 problematic variables removed
table(training$classe) # class balance seems to be ok
table(f_train$new_window
uc <- apply(f_train, 2, function(x) length(unique(x)))
dim(f_train) # 34 problematic variables removed
table(training$classe) # class balance seems to be ok
table(f_train$new_window)
table(f_train$new_window)
table(f_train$new_window) # let's keep it
f_train <- f_train[ , -1]
nzv <- nearZeroVar(f_train, saveMetrics = TRUE) # it suggests we drop the "new_window" variable
nzw # it suggests we drop the "new_window" variable
nzv # it suggests we drop the "new_window" variable
f_train <- training[ , -(1:5)] # f, for filtered
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
empties <- apply(f_train, 2, function(x) sum(x == "")) > .95*nrow(f_train)
f_train <- f_train[ , !empties]
nzv <- nearZeroVar(f_train, saveMetrics = TRUE)
head(nzv) # it suggests we drop the "new_window" variable
nzv <- nearZeroVar(f_train)
nzv # "new_window" variable
table(f_train)[,1] # looks imbalanced, let's drop it
table(f_train[,1]) # looks imbalanced, let's drop it
table(training$classe) # class balance seems to be ok
nzv <- nearZeroVar(f_train[,-55])
f_train <- f_train[ , -1]
cor(f_train[ , -54])
set.seed(88888888)
set.seed(88888888)
control <- trainControl(method="repeatedcv", number=10, repeats=5)
modelLVQ <- train(classe ~ ., data=f_train, method="lvq", trControl=control)
### Practical Machine Learning
### by Johns Hopkins University
## Course project
# Weight Lifting Exercises Dataset
training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# required libraries
# install.packages("caret", dependencies = TRUE)
library(caret)
str(training) # y = "classe"
training$classe <- as.factor(training$classe)
table(training$classe) # class balance seems to be ok
# we can remove the index, names, and most likely the timestamps
f_train <- training[ , -(1:5)] # f, for filtered
# there are many NAs, can we remove those columns?
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
# total NAs per column set to 95% threshold to keep columns where we may be able
# to impute missing values later
sum(is.na(f_train)) # looks like all columns had > 95% NAs
# any columns with more than 95% blanks should be removed
empties <- apply(f_train, 2, function(x) sum(x == "")) > .95*nrow(f_train)
f_train <- f_train[ , !empties]
sum(f_train == "") # looks good
# we could have probably eliminated problematic variables with nearZeroVar
# let's see what it tells us now
nzv <- nearZeroVar(f_train[,-55])
nzv # 1 = "new_window" variable
table(f_train[,1]) # ok, it's nzv, let's drop it
f_train <- f_train[ , -1]
# at this point we can continue to preprocess, such as removing correlated
# predictors -say if we wanted to build a partial least squares model
# or we can center and scale the variables for PCA, but we can use preProcess
# in the train function. we can avoid having to preprocess the test set
# ok let's try out some models!
# Learning Vector Quantization (LVQ)
# Stochastic Gradient Boosting aka Gradient Boosted Machine (GBM)
# Support Vector Machine (SVM)
# Tree
set.seed(88888888)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
modelLVQ <- train(classe ~ ., data = f_train, method = "lvq", trControl = control)
install.packages("class")
install.packages("class")
install.packages(c("curl", "Rfast"))
?tune.control
llibrary(e1071)
library(e1071)
?tune.control
?xgboost
?xgboost::xgbboost
?xgboost::xgboost
?tuneGrid
library("caret", lib.loc="C:/R/JASP 0.8.1.2/R/library")
?tuneGrid
### Practical Machine Learning
### by Johns Hopkins University
## Course project
# Weight Lifting Exercises Dataset
training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# required libraries
# install.packages(c("e1071", "caret", "doSNOW", "ipred", "xgboost"),
dependencies = TRUE)
library(caret); library(doSNOW) #for training in parallel
str(training) # y = "classe"
training$classe <- as.factor(training$classe)
table(training$classe) # class balance seems to be ok
# we can remove the index, names, and most likely the timestamps
f_train <- training[ , -(1:5)] # f, for filtered
# there are many NAs, can we remove those columns?
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
# total NAs per column set to 95% threshold to keep columns where we may be able
# to impute missing values later
sum(is.na(f_train)) # looks like all columns had > 95% NAs
# any columns with more than 95% blanks should be removed
empties <- apply(f_train, 2, function(x) sum(x == "")) > .95*nrow(f_train)
f_train <- f_train[ , !empties]
sum(f_train == "") # looks good
# we could have probably eliminated problematic variables with nearZeroVar
# let's see what it tells us now
nzv <- nearZeroVar(f_train[,-55])
nzv # 1 = "new_window" variable
table(f_train[,1]) # ok, it's nzv, let's drop it
f_train <- f_train[ , -1]
# at this point we can continue to preprocess, such as removing correlated
# predictors -say if we wanted to build a partial least squares model
# or we can center and scale the variables for PCA, but we can use preProcess
# in the train function. we can avoid having to preprocess the test set
# ok let's try out some models!
# Learning Vector Quantization (LVQ)
# Stochastic Gradient Boosting aka Gradient Boosted Machine (GBM)
# Support Vector Machine (SVM) from e1071
# CART
set.seed(88888888)
control <- trainControl(method = "repeatedcv",
number=10,
repeats=3,
search = "grid")
tune.grid <- expand.grid(eta = c(0.05, 0.075, 0.1),
nrounds = c(50, 75, 100),
max_depth = 6:8,
min_child_weight = c(2.0, 2.25, 2.5),
colsample_bytree = c(0.3, 0.4, 0.5),
gamma = 0,
subsample = 1)
cl <- makeCluster(2, type = "SOCK")
# Register cluster so that caret will know to train in parallel.
registerDoSNOW(cl)
modelGBM <- train(classe ~ ., data = f_train, method = "xgboost",
trControl = control, tuneGrid = tune.grid, verbose = FALSE)
modelGBM <- train(classe ~ ., data = f_train, method = "xgbTree",
trControl = control, tuneGrid = tune.grid, verbose = FALSE)
install.packages(c("curl", "Rfast"))
### Practical Machine Learning
### by Johns Hopkins University
## Course project
# Weight Lifting Exercises Dataset
training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# required libraries
# install.packages(c("e1071", "caret", "doSNOW", "ipred", "xgboost"),
dependencies = TRUE)
library(caret); library(doSNOW) #for training in parallel
str(training) # y = "classe"
training$classe <- as.factor(training$classe)
table(training$classe) # class balance seems to be ok
# we can remove the index, names, and most likely the timestamps
f_train <- training[ , -(1:5)] # f, for filtered
# there are many NAs, can we remove those columns?
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
# total NAs per column set to 95% threshold to keep columns where we may be able
# to impute missing values later
sum(is.na(f_train)) # looks like all columns had > 95% NAs
# any columns with more than 95% blanks should be removed
empties <- apply(f_train, 2, function(x) sum(x == "")) > .95*nrow(f_train)
f_train <- f_train[ , !empties]
sum(f_train == "") # looks good
# we could have probably eliminated problematic variables with nearZeroVar
# let's see what it tells us now
nzv <- nearZeroVar(f_train[,-55])
nzv # 1 = "new_window" variable
table(f_train[,1]) # ok, it's nzv, let's drop it
f_train <- f_train[ , -1]
# at this point we can continue to preprocess, such as removing correlated
# predictors -say if we wanted to build a partial least squares model
# or we can center and scale the variables for PCA, but we can use preProcess
# in the train function. we can avoid having to preprocess the test set
# ok let's try out some models!
# Learning Vector Quantization (LVQ)
# Stochastic Gradient Boosting aka Gradient Boosted Machine (GBM)
# Support Vector Machine (SVM) from e1071
# CART
set.seed(88888888)
control <- trainControl(method = "repeatedcv",
number=10,
repeats=3,
search = "grid")
tune.grid <- expand.grid(eta = c(0.05, 0.075, 0.1),
nrounds = c(50, 75, 100),
max_depth = 6:8,
min_child_weight = c(2.0, 2.25, 2.5),
colsample_bytree = c(0.3, 0.4, 0.5),
gamma = 0,
subsample = 1)
### Practical Machine Learning
### by Johns Hopkins University
## Course project
# Weight Lifting Exercises Dataset
training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
# required libraries
# install.packages(c("e1071", "caret", "doSNOW", "ipred", "xgboost"),
dependencies = TRUE)
library(caret); library(doSNOW) #for training in parallel
str(training) # y = "classe"
training$classe <- as.factor(training$classe)
table(training$classe) # class balance seems to be ok
# we can remove the index, names, and most likely the timestamps
f_train <- training[ , -(1:5)] # f, for filtered
# there are many NAs, can we remove those columns?
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
# total NAs per column set to 95% threshold to keep columns where we may be able
# to impute missing values later
sum(is.na(f_train)) # looks like all columns had > 95% NAs
# any columns with more than 95% blanks should be removed
empties <- apply(f_train, 2, function(x) sum(x == "")) > .95*nrow(f_train)
f_train <- f_train[ , !empties]
sum(f_train == "") # looks good
# we could have probably eliminated problematic variables with nearZeroVar
# let's see what it tells us now
nzv <- nearZeroVar(f_train[,-55])
nzv # 1 = "new_window" variable
table(f_train[,1]) # ok, it's nzv, let's drop it
f_train <- f_train[ , -1]
# at this point we can continue to preprocess, such as removing correlated
# predictors -say if we wanted to build a partial least squares model
# or we can center and scale the variables for PCA, but we can use preProcess
# in the train function. we can avoid having to preprocess the test set
# ok let's try out some models!
# Learning Vector Quantization (LVQ)
# Stochastic Gradient Boosting aka Gradient Boosted Machine (GBM)
# Support Vector Machine (SVM) from e1071
# CART
set.seed(88888888)
control <- trainControl(method = "repeatedcv",
number=10,
repeats=3,
search = "grid")
tune.grid <- expand.grid(eta = c(0.05, 0.075, 0.1),
nrounds = c(50, 75, 100),
max_depth = 6:8,
min_child_weight = c(2.0, 2.25, 2.5),
colsample_bytree = c(0.3, 0.4, 0.5),
gamma = 0,
subsample = 1)
modelGBM <- train(classe ~ ., data = f_train, method = "xgbTree",
trControl = control, tuneGrid = tune.grid, verbose = FALSE)
install.packages(c("e1071", "caret", "doSNOW", "ipred", "xgboost"),
dependencies = TRUE)
library(caret)
library(caret)
str(training) # y = "classe"
training$classe <- as.factor(training$classe)
table(training$classe) # class balance seems to be ok
# we can remove the index, names, and most likely the timestamps
f_train <- training[ , -(1:5)] # f, for filtered
# there are many NAs, can we remove those columns?
f_train <- f_train[ , colSums(!is.na(f_train)) > .95*nrow(f_train)]
# total NAs per column set to 95% threshold to keep columns where we may be able
# to impute missing values later
sum(is.na(f_train)) # looks like all columns had > 95% NAs
# any columns with more than 95% blanks should be removed
empties <- apply(f_train, 2, function(x) sum(x == "")) > .95*nrow(f_train)
f_train <- f_train[ , !empties]
sum(f_train == "") # looks good
# we could have probably eliminated problematic variables with nearZeroVar
# let's see what it tells us now
nzv <- nearZeroVar(f_train[,-55])
nzv # 1 = "new_window" variable
table(f_train[,1]) # ok, it's nzv, let's drop it
f_train <- f_train[ , -1]
# at this point we can continue to preprocess, such as removing correlated
# predictors -say if we wanted to build a partial least squares model
# or we can center and scale the variables for PCA, but we can use preProcess
# in the train function. we can avoid having to preprocess the test set
# ok let's try out some models!
# Learning Vector Quantization (LVQ)
# Stochastic Gradient Boosting aka Gradient Boosted Machine (GBM)
# Support Vector Machine (SVM) from e1071
# CART
set.seed(88888888)
control <- trainControl(method = "repeatedcv",
number=10,
repeats=3,
search = "grid")
tune.grid <- expand.grid(eta = c(0.05, 0.075, 0.1),
nrounds = c(50, 75, 100),
max_depth = 6:8,
min_child_weight = c(2.0, 2.25, 2.5),
colsample_bytree = c(0.3, 0.4, 0.5),
gamma = 0,
subsample = 1)
modelGBM <- train(classe ~ ., data = f_train, method = "xgbTree",
trControl = control, tuneGrid = tune.grid, verbose = FALSE)
modelGBM <- train(classe ~ ., data = f_train, method = "xgbTree")
modelCART <- train(classe ~ ., data = f_train, method = "rpart")
modelSVM <- train(classe ~ ., data = f_train, method = "svmRadial")
modelLVQ <- train(classe ~ ., data = f_train, method = "lvq")
library(rattle)
fancyRpartPlot(modelCART$finalModel)
install.packages("rattle")
library(rattle)
install.packages("rattle", dependencies = TRUE)
install.packages("rattle", dependencies = TRUE)
install.packages("ctv", dependencies = TRUE)
library(ctv)
install.views("Econometrics")
library(rattle)
library(e1071)
modelSVM <- svm(classe ~ ., data = f_train)
modelQDA <- train(classe ~ ., data = f_train, method = "qda")
modelBLR <- train(classe ~ ., data = f_train, method = "LogitBoost")
library(caret)
modelGBM <- train(classe ~ ., data = f_train, method = "gbm")
rm(training)
modelQDA <- train(classe ~ ., data = f_train, method = "qda")
install.packages("MASS", dependencies = TRUE)
install.packages("MASS", dependencies = TRUE)
library(caret)
install.packages("caret", dependencies = TRUE)
library(caret)
install.packages("lme4", dependencies = TRUE)
library(caret)
install.packages("quantreg", dependencies = TRUE)
library(caret)
library(caret)
install.packages("Rcmdr", dependencies = TRUE)
modelQDA <- train(classe ~ ., data = f_train, method = "qda")
modelBLR <- train(classe ~ ., data = f_train, method = "LogitBoost")
library(rattle)
fancyRpartPlot(modelCART$finalModel)
results <- resamples(list(QDA=modelQDA, GBM=modelGBM, SVM=modelSVM,
CART=modelCART, BLR=modelBLR))
results <- resamples(list(QDA=modelQDA, GBM=modelGBM,
CART=modelCART, BLR=modelBLR))
results$values
summary(results)
bwplot(results)
#5
set.seed(3523)
library(AppliedPredictiveModeling); library(caret); library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = .75)[[1]]
training = concrete[ inTrain,]
testing <- concrete[-inTrain,]
set.seed(325)
mod_svm <- svm(CompressiveStrength ~ ., data = concrete)
pred_svm <- predict(mod_svm, testing)
forecast::accuracy(pred_svm, testing$CompressiveStrength)
install.packages("AppliedPredictiveModeling", dependencies = TRUE)
#5
set.seed(3523)
library(AppliedPredictiveModeling); library(caret); library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = .75)[[1]]
training = concrete[ inTrain,]
testing <- concrete[-inTrain,]
set.seed(325)
mod_svm <- svm(CompressiveStrength ~ ., data = concrete)
pred_svm <- predict(mod_svm, testing)
forecast::accuracy(pred_svm, testing$CompressiveStrength)
confusionMatrix(testing$classe, predict(modelSVM))
testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
confusionMatrix(testing$, predict(modelSVM))
training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
View(testing)
View(training)
confusionMatrix(testing$, predict(modelSVM))
confusionMatrix(training$classe, predict(modelSVM))
str(confusionMatrix(training$classe, predict(modelSVM)))
confusionMatrix(training$classe, predict(modelSVM))$overall[1]
confusionMatrix(training$classe, predict(modelGBM))$overall[1]
confusionMatrix(training$classe, predict(modelSVM))$overall[1]
confusionMatrix(training$classe, predict(modelBLR))$overall[1]
confusionMatrix(training$classe, predict(modelQDA))$overall[1]
str(modelSVm)
str(modelSVM)
stacked <- data.frame(predict(modelSVM),
predict(modelGBM),
predict(modelBLR),
predict(modelQDA),
classe = training$classe)
View(stacked)
View(stacked)
predictions <- predict(modelGBM, training)
predictions
predictions <- predict(modelGBM, testing)
predictions
install.packages(c("foreign", "np", "RUnit"))
install.packages("np")
getwd()
dir()
getwd()
setwd("C:/R/pml-nl")
load("pml-nl.Rdata"")
load("pml-nl.Rdata")
